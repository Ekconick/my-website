---
title: "JSC370 Final Project"
author: "Yuxuan Wang"
output: 
    html_document:
        toc: TRUE
        toc_float: TRUE
---

This is my JSC370 Final Project website.



## Showcasing plots {.tabset}

### Figure 1
```{r echo=FALSE, message=FALSE,warning=FALSE}
library(tidyverse)
library(plotly)
library(widgetframe)
library(tidytext)
sb_locs <- read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/starbucks-locations.csv",show_col_types = FALSE)

sb_nutr <- read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/starbucks-menu-nutrition.csv",show_col_types = FALSE)

usa_pop <- read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/us_state_pop.csv",show_col_types = FALSE)

usa_states<-read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/states.csv",show_col_types = FALSE)
# interactive plot 1
sb_usa <- sb_locs |> filter(Country=="US")

sb_locs_state <- sb_usa |>
  group_by(`State/Province`) |>
  rename(state=`State/Province`) |>
  summarize(n_stores=n())

# need state abbreviations
usa_pop_abbr <- 
  full_join(usa_pop, usa_states, 
            by = join_by(state == State)
  ) 

sb_locs_state <- full_join(sb_locs_state, usa_pop_abbr,
                           by = join_by (state == Abbreviation))


### Get topwords from menu items ###

topwords <- sb_nutr |>
  unnest_tokens(word, Item, token="words") |>
  group_by(word) |>
  summarise(word_frequency = n()) |>
  arrange(across(word_frequency, desc)) |>
  head(10)
p1 <- ggplot(sb_locs_state, aes(x=population, y=n_stores, color=state))+
  geom_point(alpha = 0.5)
ggplotly(p1)

```

### Figure 2

```{r echo=FALSE,warning=FALSE}
# interactive plot 2
sb_nutr_summary <- sb_nutr %>%
  group_by(Calories, Category) %>%
  summarise(Count = n(), .groups = 'drop')

p2 <- ggplot(sb_nutr_summary, aes(x=Calories, y=Count, fill=Category))+
  geom_histogram(stat = "identity", position = "stack", alpha=0.5)
ggplotly(p2)
```

{-}

