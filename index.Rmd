---
title: "JSC370 Final Project"
author: "Yuxuan Wang"
output: 
    html_document:
        toc: TRUE
        toc_float: TRUE
---

# Project description

The real estate markets, present an interesting opportunity for data analysts to analyze and predict where property prices are moving towards. Prediction of property prices is becoming increasingly crucial, offering valuable insights into both the broader market's trajectory and the economic health of a nation. This project tackles the classic problem of house price prediction using machine learning and statistical methods, with a specific focus on identifying the key factors influencing housing prices in the United States. Furthermore, we dive into a case study of Seattle, comparing the city's housing market dynamics to those of the broader national market, and provides a more comprehensive understanding of the factors affecting property prices at both local and national levels.



## Showcasing plots {.tabset}

### Figure 1
```{r echo=FALSE, message=FALSE,warning=FALSE}
library(tidyverse)
library(plotly)
library(widgetframe)
library(tidytext)
sb_locs <- read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/starbucks-locations.csv",show_col_types = FALSE)

sb_nutr <- read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/starbucks-menu-nutrition.csv",show_col_types = FALSE)

usa_pop <- read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/us_state_pop.csv",show_col_types = FALSE)

usa_states<-read_csv("https://raw.githubusercontent.com/JSC370/JSC370-2024/main/labs/lab11/states.csv",show_col_types = FALSE)
# interactive plot 1
sb_usa <- sb_locs |> filter(Country=="US")

sb_locs_state <- sb_usa |>
  group_by(`State/Province`) |>
  rename(state=`State/Province`) |>
  summarize(n_stores=n())

# need state abbreviations
usa_pop_abbr <- 
  full_join(usa_pop, usa_states, 
            by = join_by(state == State)
  ) 

sb_locs_state <- full_join(sb_locs_state, usa_pop_abbr,
                           by = join_by (state == Abbreviation))


### Get topwords from menu items ###

topwords <- sb_nutr |>
  unnest_tokens(word, Item, token="words") |>
  group_by(word) |>
  summarise(word_frequency = n()) |>
  arrange(across(word_frequency, desc)) |>
  head(10)
p1 <- ggplot(sb_locs_state, aes(x=population, y=n_stores, color=state))+
  geom_point(alpha = 0.5)
ggplotly(p1)

```

### Figure 2

```{r echo=FALSE,warning=FALSE}
# interactive plot 2
sb_nutr_summary <- sb_nutr %>%
  group_by(Calories, Category) %>%
  summarise(Count = n(), .groups = 'drop')

p2 <- ggplot(sb_nutr_summary, aes(x=Calories, y=Count, fill=Category))+
  geom_histogram(stat = "identity", position = "stack", alpha=0.5)
ggplotly(p2)
```

{-}

